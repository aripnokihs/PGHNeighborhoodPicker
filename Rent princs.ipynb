{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43dd83d4-de1c-471e-a280-8e9f430aa20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Pages:   0%|          | 0/30 [00:03<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Base URL for rental listings in Pittsburgh\n",
    "base_url = \"https://www.realtor.com/apartments/Pittsburgh_PA\"\n",
    "\n",
    "# Set up headers to mimic a real browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Create a list to hold rental data\n",
    "rental_data = []\n",
    "\n",
    "# Specify the number of pages to scrape\n",
    "num_pages = 30  # Adjust this based on the number of available pages\n",
    "\n",
    "def extract_zip_code(address):\n",
    "    \"\"\"Extracts the zip code from the address string.\"\"\"\n",
    "    match = re.search(r'\\b\\d{5}\\b', address)  # Regex to find a 5-digit zip code\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def average_price(price_text):\n",
    "    \"\"\"Calculates the average price from a price range string.\"\"\"\n",
    "    # Check if the price is a range (e.g., \"$1,200 - $1,500\")\n",
    "    if \" - \" in price_text:\n",
    "        prices = [float(p.replace('$', '').replace(',', '').strip()) for p in price_text.split(' - ')]\n",
    "        return sum(prices) / len(prices)  # Return average price as a float\n",
    "    else:\n",
    "        return float(price_text.replace('$', '').replace(',', '').strip())  # Return single price as a float\n",
    "\n",
    "# Use tqdm to create a progress bar\n",
    "for page in tqdm(range(1, num_pages + 1), desc=\"Fetching Pages\"):\n",
    "    # Construct the URL for the current page\n",
    "    url = f\"{base_url}/pg-{page}\"\n",
    "\n",
    "    # Retry logic\n",
    "    retries = 1\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            # Send a GET request to the website\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                # Parse the HTML content\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                # Find all the listings on the page\n",
    "                address_divs = soup.find_all('div', class_='truncate-line', attrs={'data-testid': 'card-address-2'})\n",
    "                price_spans = soup.find_all('span', class_='base__StyledType-rui__sc-108xfm0-0 jywYrs')\n",
    "\n",
    "                # Check if any addresses or prices were found\n",
    "                if not address_divs or not price_spans:\n",
    "                    print(f\"No addresses or prices found on page {page}.\")\n",
    "                    break  # Exit if nothing is found\n",
    "\n",
    "                # Iterate through addresses and prices\n",
    "                for address, price in zip(address_divs, price_spans):\n",
    "                    address_text = address.get_text(strip=True)\n",
    "                    price_text = price.get_text(strip=True)  # Get the price text\n",
    "                    rental_data.append({\n",
    "                        'Address': address_text,\n",
    "                        'Price': average_price(price_text),  # Use the average price function\n",
    "                        'zipcode': extract_zip_code(address_text)  # Extract zip code\n",
    "                    })\n",
    "\n",
    "                # Respectful scraping: wait for a short period between requests\n",
    "                time.sleep(0)  # Adjust this time as needed\n",
    "                break  # Exit the retry loop if successful\n",
    "            else:\n",
    "                print(f\"Failed to retrieve data from page {page}: {response.status_code}\")\n",
    "                time.sleep(2)  # Wait before retrying\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Connection error: {e}. Retrying...\")\n",
    "            time.sleep(2)  # Wait before retrying\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "rental_df = pd.DataFrame(rental_data)\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "rental_df.to_csv('pittsburgh_rental_prices.csv', index=False)\n",
    "\n",
    "print(\"Data saved to pittsburgh_rental_prices.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b4d4e-4599-4bbd-9681-445af2641780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
